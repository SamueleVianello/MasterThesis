\chapter{Calibration of the Models}
\label{chpr:calibration}

In this chapter we will explain how the different models were calibrated and what difficulties were overcome. Empirical results are included for each section.

\textbf{*****aggiungere commento su diversi tipi di calibrazione e in particolare sul fatto che calibriamo su timeseries*****}
\bigskip

\section{Maximum Likelihood Calibration}
The calibration method that we implemented is the \textit{maximum likelihood} approach, which is a statistical method to obtain the parameters of a target distribution family that best approximate the unknown distribution of the observed data.

Let us call $X = \left\lbrace x_1, x_2, ... , x_N \right\rbrace$ the set of available observations and let $\psi= \left\lbrace \alpha_1, \alpha_2, ... \right\rbrace $ the set of parameters of the distribution $ \mathcal{D}$ that we want to calibrate.
Moreover, define $f_\mathcal{D} (x ; \psi)$ to be the probability density function (pdf) of distribution $\mathcal{D}$ with parameters $\psi$ computed at $x \in \mathbb{D}$, where $\mathbb{D}$ is the domain of the density function.

Our aim is to find the best set of parameters $\psi$ such that we can describe $X$ as samples taken from $\mathcal{D}$:
\begin{equation}
x_i \sim \mathcal{D} (\psi), \: i = 1, \dots, N.
\end{equation}

The estimation of the parameter set $\psi$ can then be obtained by:
\begin{equation}
	\hat{\psi} = \argmax_{\psi \in \Psi} \:\mathcal{L}(\psi |  X),
\end{equation}

where $\mathcal{L}(\psi |  X)$ is the likelihood function for distribution $\mathcal{D}(\psi)$ given the observed data $X$.

In the case that the data in $X$ are i.i.d. we have that the likelihood function can be computed as the product of the probability density function computed at each observation $x_i$:

\begin{equation}
\label{eq:log_likelihood}
\mathcal{L}(\psi |  X) = \prod_{i=1}^{N} f_{ \mathcal{D}}(x_{i}; \psi).
\end{equation}

In practice, it is often common to consider the \textit{log-likelihood} function $\ell(\psi |  X)  = \log \mathcal{L}(\psi |  X)$. The natural logarithm is a monotonic function so the maximum of the log-likelihood function is achieved in the same point as the basic likelihood function.\footnote{By how the likelihood function is defined, it can attain only positive values so that the logarithm of  $\mathcal{L}(\psi |  X)$ is always well defined.}
Taking the logarithm of \eqref{eq:likelihood} also simplifies the expression in that the product now becomes a sum:
\begin{equation}
\label{eq:likelihood}
\ell (\psi |  X) =\mathcal{L}(\psi |  X) = \sum_{i=1}^{N} \log f_{ \mathcal{D}}(x_{i}; \psi).
\end{equation}

The issues that arise from the definition of a maximum likelihood estimator are mainly two.
The first problem is that to use equation \eqref{eq:likelihood} we need to know the pdf of the distribution: this might not always be the case with complicated models that only have an explicit expression for their characteristic function. This is what happens for Heston and Bates model, and, as we will see, we are going to need to invert the chf via Fourier inversion and obtain the pdf numerically.

The second issue is that we need to solve a maximization problem in order to obtain an estimate for the parameters of the distribution: it is well known how optimization routines might perform well for some special circumstance and badly under other, especially when the number of parameters increases. The trade-off is, as usual, between fast computations and robustness of the optimization. To solve this, we will opt for a combination of global and local optimizers.





\section{Calibration of Merton Model}
Let us start by considering how we calibrated the jump diffusion model by Merton. 
We will first present how to obtain the parameters for a single asset model and then move to a multi-asset one.



\subsection{Single Asset Merton Calibration}
As we already introduced, the calibration method that we used is the maximum likelihood approach.

We are going to calibrate the values of the 5 parameters $\psi= \left\{ \mu, \sigma, \mu_J, \sigma_J, \lambda \right\}$ of the jump diffusion model based on the observations of the log-returns $\Delta x_i = \log \frac{S_i}{S_{i-1}}$ for each time interval $\Delta t$. In our analysis, since we are going to use \textit{daily} log-returns, $\Delta t = 1/255$. 

Considering daily log-returns allows us to assume that the different samples of $\Delta x$ are independent and identically distributed according to the distribution of log-returns in Merton model given in \eqref{transitional}.
For ease of reading, we present it again here:
\begin{equation}
\label{eq:merton_full_pdf}
f_{\Delta x } (x; \psi) = \sum_{k=0}^{\infty} \mathbb{P}(N = k) f_{\Delta x | N = k}(x ; \psi) .
\end{equation}

The formula represents an infinite mixture of Gaussian distributions, due to the infinite possible realization of the Poisson variable that accounts for the arrival of jumps. 
This fact has a great downside in terms of maximum likelihood estimation. As discussed in \cite{HONORE1998}, the infinite Gaussian mixture causes the problem of maximizing the (log-)likelihood to be unbounded and thus intractable.

To solve this issue we can introduce a first order approximation, as it has been proposed in \cite{BALLTOROUS1983}. 
Since we are considering a small time interval $\Delta t $, only the first terms of the series in \eqref{eq:merton_full_pdf} become significant. 
In particular, we have that the probabilities to have $k = 0, 1, 2$ jumps in a single time step, as presented in \eqref{eq:pois_pdf}, are:
\begin{subequations}
	\begin{align}
	\mathbb{P}(N = 0) &= e^{-\lambda \Delta t}, \\
	\mathbb{P}(N = 1) &= \lambda \Delta t \: e^{-\lambda \Delta t}, \\
	\mathbb{P}(N = 2) &= \frac{(\lambda \Delta t)^2}{2} \: e^{-\lambda \Delta t}
	\end{align}
\end{subequations}

since $N \sim Pois(\lambda \Delta t)$, which is the Poisson process counting jumps that happen in a $\Delta t$ interval.
Considering $\lambda \Delta t$ as small, we can approximate to the first order  $e^{-\lambda \Delta t} =  1 - \lambda \Delta t +  o((\lambda \Delta t)^2)$. 
We thus obtain that:
\begin{subequations}
	\begin{align}
	\mathbb{P}(N = 0) &= 1-\lambda \Delta t , \\
	\mathbb{P}(N = 1) &= \lambda \Delta t \: (1- \lambda \Delta t) = \lambda \Delta t + o((\lambda \Delta t)^2), \\
	\mathbb{P}(N = 2) &= \frac{(\lambda \Delta t)^2}{2} \: (1-\lambda \Delta t) = o((\lambda \Delta t)^2).
	\end{align}
\end{subequations}


The result is that the only relevant terms in \eqref{eq:merton_full_pdf} are the ones for $ k = 0, 1$.
The formula for the transition density thus  becomes:
\begin{equation}
f_{\Delta x} (x; \psi) = \mathbb{P}(N = 0) f_{\Delta X | N = 0}(x; \psi) + \mathbb{P}(N = 1) f_{\Delta x | N = 1}(x; \psi)
\end{equation}
We can then write this equation explicitly by considering the different distributions of the log-returns in the case of no jumps and a single jump:
\begin{equation}
\label{eq:merton_pdf}
f_{\Delta x} (x; \psi) = (1 - \lambda \Delta t) \;
f_{\mathcal{N}}\Big(x ; \widetilde{\mu}\, \Delta t, \sigma^2 \Delta t\Big) + (\lambda \Delta t)\; f_{\mathcal{N}}(x ; \widetilde{\mu}\, \Delta t + \theta, \sigma^2 \Delta t+\delta^2)
\end{equation}
where $f_{\mathcal{N}}(x ; \mu, \sigma^2)$ indicates the pdf of a Gaussian with parameters $\mathcal{N}(\mu, \sigma^2)$ compute at $x$. We used $\widetilde{\mu} = \mu - \sigma^2/2 -\lambda \mu_J$ as a simpler notation to indicate the drift term in the return dynamics.

The distribution of the sample log-returns is thus given by equation \eqref{eq:merton_pdf} and we can plug it into \eqref{eq:log_likelihood} to obtain the log-likelihood function that we are going to maximize:
\begin{equation}
\label{eq:merton_loglikelihood_single}
	\ell(\psi |  \Delta x) = \sum_{i=1}^{N} \log f_{ \Delta x}(\Delta x_{i}; \psi).
\end{equation}

One can then proceed to maximize equation \eqref{eq:merton_loglikelihood_single} to obtain the optimal parameter set $\psi$:
\begin{equation}
\hat{\psi} = \argmax_{\psi \in \Psi} \:\ell(\psi |  \Delta x)
\end{equation}
\begin{equation}
\Psi = \{ (\mu, \sigma, \mu_J, \sigma_J, \lambda) \in \mathbb{R}^5 \: |\: \sigma,\sigma_J, \lambda >0\}
\end{equation}

\subsection{Multi-asset Merton Calibration}
\label{subsec:multi_merton_cal}

We now know  how to calibrate the Merton parameters when the underlying asset is one.
In the case of multiple assets, we decided to adapt \cite{PARSIMONIOUS2011} both for the model definition and the calibration procedure.
In the referenced paper, the authors present a \textit{parsimonious approach} to the extension of Heston Model to a multi-asset framework. Since this is the approach that we will follow for the multivariate Heston calibration and for Bates as well, we decided to also perform in the same way the calibration of the parameters for Merton.
Using a common approach will allow us to better compare the results, especially in terms of the correlation structure that is what we are ultimately interested in.

The first step in the calibration algorithm is to obtain the parameters of all the single asset models that we are studying. The general way to do this was explained in the previous section. 

The next step involves computing the correlation matrix between the different Brownian motions that drive each single-asset model. 
The way this computation is carried out in \cite{PARSIMONIOUS2011} is by asset pairs: we consider each possible couple of assets and try to obtain the model correlation that best approximates the observed correlation.
Let us see how this is achieved more in detail in the case of only two assets.

The problem we are trying to solve is, given the observed sample correlation $\rho_{obs}$ between two assets' returns, find the best model correlation $\rho_{model}$ that solves $\bar{\rho}(\rho_{model}) = \rho_{obs}$.
$\bar{\rho}$ is the expectation of the correlation that we find when computing the  empirical correlation of the returns simulated using $\rho_{model}$.

More precisely, we have to simulate $N_{sim}$ different realisations of the 2-asset model in a given time period $[0, T]$ with the same $\Delta t$ that we have in the observed data, using $\rho_{model}$ as the correlation between the two driving Brownian motions. We then proceed to compute the correlation of the simulated log-returns $\rho_{scen}$ in each scenario and then we take the average of this values. What we obtain is $\bar{\rho} = \mathbb{E}[\rho_{scen}] $.

In order to simulate a two-asset Merton model, we used the following discretization for the log-returns:
\begin{subequations}
	\label{eq:merton_discretization}
	\begin{align}
	x_i^{(1)} &= x_{i-1}^{(1)} + (\mu_1 - \sigma_1^2/2 -\lambda_1 {\mu_J}_1) \Delta t + \sigma_1 \sqrt{\Delta t} \;  z_1 + N_1 {Y}_1 ,\\
	x_i^{(2)} &= x_{i-1}^{(2)} + (\mu_2 - \sigma_2^2/2 -\lambda_2 {\mu_J}_2) \Delta t + \sigma_2 \sqrt{\Delta t} \; z_2 + N_2 {Y}_2 ,
	\end{align}
\end{subequations} 
where:
\begin{itemize}
	\item $i = 1, \dots , N_{step}$ represents the i-th time-step in our simulation: $x_i = x_{t_i}$ and $N_{step} = T / \Delta t$ so that $t_i = i \Delta t$. The value of the initial return $x_{t_0}$ does not affects the final correlation so we can simply set it to zero.
	\item $z_1$ and $z_2$ are the first and second component of a Gaussian vector $\mathbf{z} = (z_1,z_2)^T$ that is distributed as $\mathbf{z} \sim \mathcal{N}_2(\mathbf{0}, Corr)$. $Corr$ is the $2 \times 2$ matrix composed of ones in the main diagonal and $\rho_{model}$ in the remaining two spots. 
	More simply, $\mathbf{z}$ is a two dimensional Gaussian with zero mean with covariance matrix equal to the correlation matrix of the model.
	\item $N_1$ and $N_2$ are in general the realizations of two Poisson random variables with parameters $\lambda_1 \Delta t$ and $\lambda_2 \Delta t$ respectively. Given our first order approximation in the density and considering small $\Delta t$,  $N_1$ and $N_2$ are actually two Bernoulli with probability of success (i.e. a jump happens) equal to $\lambda_1 \Delta t$ and $\lambda_2 \Delta t$.
	\item Finally, $Y_1$ and $Y_2$ are the jump intensities and are realisations of Gaussian variables with parameters $\mathcal{N}({\mu_J}_1, {\sigma_J}_1^2)$ and $\mathcal{N}({\mu_J}_1, {\sigma_J}_1^2)$ . 
\end{itemize}

Through \eqref{eq:merton_discretization} we can thus simulate $ x_i^{(1,k)}$ and 
$ x_i^{(2,k)}$ for $k= 1, ... ,N_{sim}$  and compute for each scenario the correlation observed from the simulated returns $\rho_{scen}^{(k)} = corr(x_i^{(1,k)}, x_i^{(2,k)})$.
From these values we can easily compute $\bar{\rho}$:
\begin{equation}
\label{eq:expected_model_correlation}
	\bar{\rho} = \mathbb{E} [\rho_{scen}] = \frac{1 }{N_{sim}} \sum_{k=1}^{N_{sim}} \rho_{scen}^{(k)}
\end{equation}


We have that implicitly the value of the \textit{expected model correlation} $\bar{\rho}$ is a function of the model correlation $\rho_{model}$. The equation we need to solve is then represented by:
\begin{equation}
\label{eq:expected_observed}
\bar{\rho}(\rho_{model}) = \rho_{obs},
\end{equation}

as we have already stated earlier in this section.

\bigskip
In the case of an $n$-asset model, we have to repeat the previous passages for all possible $n(n-1)/2 $ different pairs of assets. We then can build a $n \times n$ matrix $M$ that has ones in the main diagonal and in each element $(l,m), l \neq m$ stores the corresponding model correlation $\rho_{model}^{(l,m)}$.
This matrix may not be a well defined correlation matrix: it may happen that $M$ is not positive definite.
The last step to obtain a proper correlation matrix for our $n$-asset model is to perform some form of \textit{regularization} on $M$ that transforms it into a well defined correlation matrix: positive definite, with elements in the range $[-1,1]$ and ones in the main diagonal.

Through empirical study performed in the reference paper \cite{PARSIMONIOUS2011}, it turns out the best algorithm between the one proposed by the authors is the regularization by J\"ackel, that we briefly present here.

\bigskip
\textbf{Regularization algorithm by J\"ackel:}
\begin{enumerate}
	\item[\textbf{Input}] Model correlation matrix $M$ (not necessarily positive definite).
	\item Perform an eigenvalue decomposition on $M  = S \Lambda S^T$, where $\Lambda = diag(\lambda_l)$ and $\lambda_l$ are the eigenvalues of matrix $M$.
	\item Define $\Lambda^{'} = diag(\lambda_l^{'}$ with $\lambda_l^{'} = \max(\lambda_l, 0))$ as the diagonal matrix that contains the positive part of each eigenvalue.
	\item Create the diagonal matrix $T = diag(t_l)$ where $t_l =1 / \sum_{m} (S_{l,m})^2 \lambda_l^{'}$ .
	\item Define $B = \sqrt{T} S \sqrt{\Lambda^{'}}$.
	\item Set $\widehat{M} = B B^T$.
	\item[\textbf{Output}] Positive definite correlation matrix $\widehat{M}$.
\end{enumerate}

Hence, $\widehat{M}$ is the model correlation matrix that best represents the observed correlation values and that forms the structure of dependence between the Brownian motions that drive each asset in a multivariate Merton model.

\section{Calibration of Heston Model}
Calibrating the Heston model on time-series data presents an added difficulty since we only have data on the price process, while the model also takes into consideration the dynamics of the variance as a stochastic process. 

The problem of deducing the parameter of a \textit{non-observable} process from the observable states of a system is called \textit{filtering} and is in general a complicated numerical procedure. There are nonetheless a few studies in the literature on the subject of calibrating the Heston model through filtering. \textbf{***ADD REFERENCE***}

In our analysis we preferred to keep the same approach to the calibration for all the three models. We will thus proceed to explain how we can perform a maximum likelihood calibration in the case of stochastic volatility and, in the next section, of both jumps and stochastic volatility.

\subsection{Single Asset Heston Calibration}
The first issue that we have to overcome is that an explicit formula for the probability density function of the log-returns is not available and we have to resort to performing a Fourier inversion on the characteristic function, as we already showed in equation \eqref{eq:chf_inversion}

This allows us to have a pdf for the log-return $x_t = \log S_t $ but in order to be able to perform a maximum likelihood calibration in the same way that we did in the  previous section, we need to have the distribution for $\Delta x_t = \log (S_{t + \Delta t} / S_t)$ and make sure that they are i.i.d. so that we can apply \eqref{eq:log_likelihood}.

In order to obtain the pdf for the incremental log-returns $\Delta x_t$, we first need the distribution of  $\Delta x_{[0, t] }= \log (S_t / S_0)$ we can simply proceed as we explained in Chapter \ref{chpr:models} in the section about Heston model to get the characteristic function for $\Delta x_{[0, t] }$ conditioned on the values of $V_0$: 

\begin{equation}
\phi_{\Delta x_{[0, t] }}(u|V_0) =  \exp\{A(t,u) + C(t,u) V_0\}.
\end{equation}

The full expressions for $A(t,u)$ and $C(t,u)$ are given in \eqref{eq:heston_chf+ABC}.
Notice that we omitted the dependence on the model parameters $\psi = \{\mu, \kappa, \theta, \sigma_V, \rho \}$ for ease of notation.

\bigskip
We are now left with the distribution of $\Delta x_{[0, t] }$ as a function of $V_0$: this represents an issue since moving from $\Delta x_{[0, t] }$ to $\Delta x_t  = \Delta x_{[t, t + \Delta t]}$ we have a dependence on the value of $V_t$ which is not available. Moreover, even if data for $V_t$ was indeed available, considering different time-steps $t_i$ for $\Delta x_{t}$, the data samples of $\Delta x_{t_i}$ would not be identically distributed as they depend on levels of the variance $V_{t_i}$ which are different.

Hence the need for an \textit{unconditional} characteristic function to get rid of the dependence on initial variance. We followed the approach that was introduced in \cite{DRAGULESCU2002} of integrating out the dependence on $V_0$. The computations to obtain it were presented in Chapter \ref{chpr:models}.
The unconditional chf for the Heston model has the following expression:
\begin{equation}
 \phi_{\Delta x_t}(u) = \exp\{A(\Delta t,u) \} M_{\Gamma}(C(\Delta t,u))
\end{equation}


with $M_{\Gamma}$ as the moment generating function of a Gamma distribution:
\begin{subequations}
\begin{align}
	M_{\Gamma} (z) &= \Big(\frac{\omega}{\omega-z}\Big)^\nu \nonumber \\
	\omega&= \frac{2\kappa}{\sigma_V^2} \nonumber\\
	\nu&= \frac{2\kappa\theta}{\sigma_V^2}\nonumber
\end{align}
\end{subequations}

We now have a specific expression for the unconditional characteristic function of $\Delta x_t$ and we can obtain the corresponding density by Fourier inversion:

\begin{equation}
\label{eq:uncond_inversion}
f_{\Delta x_t}(x) = \frac{1}{2\pi}\int_{-\infty}^{+\infty}  \phi_{\Delta x_t}(i u) e^{i u x} du
\end{equation}


Another advantage of using the uncoditional chf is that since all the observed log-returns $\Delta x_i = \Delta x_{t_i} $ are considered to be sampled from the same distribution, we can numerically perform the inversion in \eqref{eq:uncond_inversion} using the Fast Fourier Transform (FFT). This allows for a great increase in the speed of the numerical computations since we can obtain the value of the pdf for all different $\Delta x_i$ with a single inversion.
The main ideas behind the FFT algorithm are explained in Appendix \ref{app:FFT}.


Now that we have the density function of $\Delta x$ with parameters $\psi = \{\mu, \kappa, \theta, \sigma_V, \rho \}$ we are able to compute the log-likelihood function by substituting \eqref{eq:uncond_inversion} in \eqref{eq:likelihood}.


In order to perform the maximization of the log-lokelihood function to calibrate the parameters, we have to make sure that the Feller condition \eqref{eq:feller_condition} is satisfied.

The MLE procedure will thus need to be performed including an additional constraint in the optimization given by Feller condition:
\begin{equation}
\hat{\psi} = \argmax_{\psi \in \Psi} \:\ell(\psi |  \Delta x)
\end{equation}
\begin{equation}
	\Psi = \{ (\mu, \kappa, \theta, \sigma_V, \rho) \in \mathbb{R}^5 \: |\: \kappa,\theta,\sigma_V >0, \rho \in [-1,1], 2\kappa\theta \geq \sigma_V \}
\end{equation}

\subsection{Multi-asset Heston Calibration}

As we already stated in this paper, the approach to extending the Heston model to $N$ assets that we are taking into consideration is the parsimonious multi-asset model introduced by Dimitroff et al. in \cite{PARSIMONIOUS2011}.
It's called \textit{parsimonious} since, as we explained in chapter \ref{chpr:models}, we are only modelling the asset-asset correlations.

The procedure to calibrating a $N$ asset model is the same that we presented in the multi-asset Merton section and consists of three parts.

Firstly, we have to calibrate all the single asset parameters by themselves. Then we can proceed to compute each asset-asset correlation by solving \eqref{eq:expected_observed} through the simulation of the realization of the log-returns in different scenarios.
Finally, we perform J\"ackel regularization algorithm to make that the final output matrix is indeed a correlation matrix.

The main steps were all presented in section \ref{subsec:multi_merton_cal}, here we will only give the details for the simulation of a two-asset Heston model.

Since we now have two processes for each asset, we have to simulate the path for both, in each time-step.
The discretized dynamics of the log-returns and the variance for a single asset are the following:

\begin{subequations}
	\label{eq:discrete_heston}
	\begin{align}
		x_i &= x_{i-1} + (\mu -  \frac{V_{i-1}}{2})\Delta t + \sqrt{V_{i-1} \Delta t} \:z_x, \\
		V_i &= V_{i-1} + \kappa(\theta - V_{i-1} )\Delta t + \sigma_V \sqrt{V_{i-1} \Delta t} \: z_V
	\end{align}
\end{subequations}
with $z_x$ and $z_V$ that are the two components of a Gaussian vector with mean zero and correlation $\rho$\footnote{In a more extensive form: $ \mathbf{z} = \begin{pmatrix}
	z_x\\ z_V
	\end{pmatrix} \sim \mathcal{N}_2 \Big(\begin{pmatrix}
	0\\ 0\end{pmatrix}, \begin{pmatrix}
	1& \rho\\ \rho&1
	\end{pmatrix} \Big)$}. 

The issue that arises when moving from a continuous dynamics to a discrete one as in \eqref{eq:discrete_heston} is that the variance $V_i$ might assume negative values even if the Feller condition is verified. This happens because the second and third term in the equation of the variance process may be so negative that combined with the first term $V_{i-1}$ the result is less than zero.
Having $V_i < 0$ causes the next update at $i+1$ to be undefined since we would have to compute the square root of a negative value in a real framework.

To solve this issue, a number of possible solutions have been proposed and are collected in \cite{LORD2010}. Among those we have:
\textit{absorption}, which consists in setting $V_i = 0$ when it is negative, \textit{reflection}, taking the absolute value $V_i = |V_i|$, and finally \textit{full truncation}, which is the solution proposed in \cite{LORD2010} and the one we will implement. It is obtained modifying \eqref{eq:discrete_heston} as following:

\begin{subequations}
	\label{eq:full_truncation}
	\begin{align}
	x_i &= x_{i-1} + (\mu -  \frac{V_{i-1}^+}{2})\Delta t + \sqrt{V_{i-1}^+ \Delta t} \:z_x, \\
	V_i &= V_{i-1} + \kappa(\theta - V_{i-1}^+ )\Delta t + \sigma_V \sqrt{V_{i-1}^+ \Delta t} \: z_V.
	\end{align}
\end{subequations}
The notation $y^+ = \max(y, 0)$ indicates the positive part of $y$. 

Equations \eqref{eq:full_truncation} represent the single asset simulation scheme but in order to calibrate the asset-asset correlations as already stated we need to simulate the time-series for a pair of assets.

The updating computations only amount to repeating the single scheme twice:
\begin{subequations}
	\label{eq:full_truncation2}
	\begin{align}
	x_i^{(1)} &= x_{i-1}^{(1)} + (\mu_1 -  \frac{\Big(V_{i-1}^{(1)}\Big)^+}{2})\Delta t + \sqrt{\Big(V_{i-1}^{(1)}\Big)^+ \Delta t} \:z_{x^{(1)}}, \\
	V_i^{(1)} &= V_{i-1}^{(1)} + \kappa_1(\theta_1 - \Big(V_{i-1}^{(1)}\Big)^+ )\Delta t + \sigma_{V^{(1)}} \sqrt{\Big(V_{i-1}^{(1)}\Big)^+ \Delta t} \: z_{V^(1)},\\
	x_i^{(2)} &= x_{i-1}^{(2)} + (\mu_2 -  \frac{\Big(V_{i-1}^{(2)}\Big)^+}{2})\Delta t + \sqrt{\Big(V_{i-1}^{(2)}\Big)^+\Delta t} \:z_{x^{(2)}}, \\
	V_i^{(2)} &= V_{i-1}^{(2)} + \kappa_2(\theta_2 - \Big(V_{i-1}^{(2)}\Big)^+ )\Delta t + \sigma_{V^{(2)}} \sqrt{\Big(V_{i-1}^{(2)}\Big)^+ \Delta t} \: z_{V^{(2)}}.
	\end{align}
\end{subequations}

The important difference with the single asset case is the correlation structure. In order to simulate the random vector $\mathbf{z} = (z_{x^{(1)}}, z_{V^{(1)}}, z_{x^{(2)}}, z_{V^{(2)}})^T$ we have to extract it from a 4-dimensional Gaussian with zero mean and covariance given by $\Sigma$ where:
\begin{equation}
	\Sigma = \begin{pmatrix}
	1 	& \rho_1 & \rho_{1,2} & \rho_{1,2} \rho_2\\
	\rho_1 & 1 & \rho_1 \rho_{1,2} & \rho_1 \rho_{1,2} \rho_2\\
	 \rho_{1,2} & \rho_1 \rho_{1,2}  & 1 & \rho_2 \\
	 \rho_{1,2} \rho_2 & \rho_1 \rho_{1,2} \rho_2&\rho_2  & 1
	\end{pmatrix}
\end{equation}

We could also use the Cholesky decomposition of $\Sigma = L L^T$ in order to obtain $\mathbf{z} = L \mathbf{\tilde{z}}$ from a standard 4-dimensional Gaussian vector $\mathbf{\tilde{z}}$. In this case matrix $L$ would be lower triangular and defined as:
\begin{equation}
	L = \begin{pmatrix}
	1&0&0&0\\
	\rho_1 & \sqrt{1- \rho_1^2} &0&0\\
	\rho_{1,2} &0&\sqrt{1-\rho_{1,2}^2}&0\\
	\rho_{1,2}\rho_2 & 0& \rho_2 \sqrt{1-\rho_{1,2}^2}&\sqrt{1- \rho_2^2} 
	\end{pmatrix}.
\end{equation}

From here on, the procedure is the same as for Merton:
we need to solve \eqref{eq:expected_observed} for every possible asset pair to obtain the model correlation M.

The final step is to apply  J\"ackel regularization algorithm to obtain a valid correlation matrix $\widehat{M}$.

